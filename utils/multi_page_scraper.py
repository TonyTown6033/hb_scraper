"""å¤šé¡µçˆ¬è™«å·¥å…· - æ”¯æŒåˆ†é¡µçˆ¬å–å’Œæ–­ç‚¹ç»­ä¼ """

import json
import time
from pathlib import Path
from typing import List, Dict, Optional
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from utils.logger import get_logger


class MultiPageScraper:
    """å¤šé¡µçˆ¬è™«ç®¡ç†å™¨"""

    def __init__(self, driver):
        """
        åˆå§‹åŒ–å¤šé¡µçˆ¬è™«

        Args:
            driver: Selenium WebDriver å®ä¾‹
        """
        self.driver = driver
        self.progress_file = Path("data/output/scrape_progress.json")
        self.logger = get_logger()

    def has_next_page(self) -> bool:
        """
        æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ

        Returns:
            bool: æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
        """
        try:
            # æŸ¥æ‰¾"ä¸‹ä¸€é¡µ"æŒ‰é’® - ä½¿ç”¨ data-test å±æ€§
            next_buttons = self.driver.find_elements(
                By.CSS_SELECTOR,
                '[data-test="button-next"]'
            )

            if not next_buttons:
                return False

            # æ£€æŸ¥æŒ‰é’®æ˜¯å¦ç¦ç”¨
            next_button = next_buttons[0]
            is_disabled = (
                next_button.get_attribute("disabled") == "true" or
                next_button.get_attribute("aria-disabled") == "true" or
                "disabled" in (next_button.get_attribute("class") or "")
            )

            return not is_disabled

        except Exception as e:
            print(f"  â†’ æ£€æŸ¥ä¸‹ä¸€é¡µæ—¶å‡ºé”™: {e}")
            return False

    def get_current_page_number(self) -> int:
        """
        è·å–å½“å‰é¡µç 

        Returns:
            int: å½“å‰é¡µç ï¼Œè·å–å¤±è´¥è¿”å› 1
        """
        try:
            # å°è¯•ä»URLå‚æ•°è·å–
            current_url = self.driver.current_url
            if "page=" in current_url:
                import re
                match = re.search(r'page=(\d+)', current_url)
                if match:
                    return int(match.group(1))

            # å°è¯•ä»åˆ†é¡µå…ƒç´ è·å–
            current_page_elements = self.driver.find_elements(
                By.CSS_SELECTOR,
                'button[aria-current="page"], a[aria-current="page"]'
            )
            if current_page_elements:
                return int(current_page_elements[0].text.strip())

            return 1

        except Exception as e:
            print(f"  â†’ è·å–é¡µç æ—¶å‡ºé”™: {e}")
            return 1

    def _handle_cookie_popup(self):
        """å¤„ç†å¯èƒ½å‡ºç°çš„ Cookie å¼¹çª—"""
        try:
            # å°è¯•æŸ¥æ‰¾å¹¶å…³é—­ Cookie å¼¹çª—
            cookie_selectors = [
                "//button[contains(text(), 'Yes I Accept')]",
                "//button[contains(text(), 'Accept')]",
                "//button[@id='onetrust-accept-btn-handler']",
                "#onetrust-accept-btn-handler",
            ]
            
            for selector in cookie_selectors:
                try:
                    if selector.startswith("//"):
                        button = self.driver.find_element(By.XPATH, selector)
                    else:
                        button = self.driver.find_element(By.CSS_SELECTOR, selector)
                    
                    if button.is_displayed():
                        button.click()
                        print("  â†’ å·²å…³é—­ Cookie å¼¹çª—")
                        time.sleep(1)
                        return True
                except:
                    continue
            
            return False
        except Exception as e:
            return False

    def go_to_next_page(self) -> bool:
        """
        è·³è½¬åˆ°ä¸‹ä¸€é¡µ

        Returns:
            bool: æ˜¯å¦æˆåŠŸè·³è½¬
        """
        try:
            if not self.has_next_page():
                return False

            # è·å–å½“å‰é¡µç 
            current_page = self.get_current_page_number()

            # å¤„ç†å¯èƒ½å‡ºç°çš„ Cookie å¼¹çª—
            self._handle_cookie_popup()

            # ç‚¹å‡»"ä¸‹ä¸€é¡µ"æŒ‰é’® - ä½¿ç”¨ data-test å±æ€§
            next_button = self.driver.find_element(
                By.CSS_SELECTOR,
                '[data-test="button-next"]'
            )

            # æ»šåŠ¨åˆ°æŒ‰é’®ä½ç½®
            self.driver.execute_script("arguments[0].scrollIntoView({block: 'center'});", next_button)
            time.sleep(1)

            # ä½¿ç”¨ JavaScript ç‚¹å‡»(é¿å…è¢«é®æŒ¡)
            try:
                next_button.click()
            except Exception as click_error:
                # å¦‚æœæ™®é€šç‚¹å‡»å¤±è´¥,ä½¿ç”¨ JavaScript ç‚¹å‡»
                print("  â†’ æ™®é€šç‚¹å‡»å¤±è´¥,å°è¯• JavaScript ç‚¹å‡»...")
                self.driver.execute_script("arguments[0].click();", next_button)
            
            print(f"\nâ†’ ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®...")

            # ç­‰å¾…é¡µé¢åŠ è½½
            time.sleep(3)

            # ç­‰å¾…äº§å“å¡ç‰‡é‡æ–°åŠ è½½ - ä½¿ç”¨æ­£ç¡®çš„é€‰æ‹©å™¨
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test="product-card"]'))
            )

            # éªŒè¯æ˜¯å¦æˆåŠŸè·³è½¬
            new_page = self.get_current_page_number()
            if new_page > current_page or new_page == 1:  # æœ‰äº›ç½‘ç«™é‡ç½®é¡µç 
                print(f"âœ“ æˆåŠŸè·³è½¬åˆ°ç¬¬ {new_page} é¡µ")
                return True
            else:
                print(f"âœ— é¡µç æœªå˜åŒ–ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                return False

        except Exception as e:
            print(f"âœ— è·³è½¬ä¸‹ä¸€é¡µå¤±è´¥: {e}")
            return False

    def save_progress(self, data: Dict):
        """
        ä¿å­˜çˆ¬å–è¿›åº¦

        Args:
            data: è¿›åº¦æ•°æ®
        """
        try:
            self.progress_file.parent.mkdir(parents=True, exist_ok=True)
            with open(self.progress_file, "w", encoding="utf-8") as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"  â†’ ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

    def load_progress(self) -> Optional[Dict]:
        """
        åŠ è½½çˆ¬å–è¿›åº¦

        Returns:
            Dict: è¿›åº¦æ•°æ®ï¼Œä¸å­˜åœ¨è¿”å› None
        """
        try:
            if self.progress_file.exists():
                with open(self.progress_file, "r", encoding="utf-8") as f:
                    return json.load(f)
        except Exception as e:
            print(f"  â†’ åŠ è½½è¿›åº¦å¤±è´¥: {e}")
        return None

    def clear_progress(self):
        """æ¸…é™¤è¿›åº¦æ–‡ä»¶"""
        try:
            if self.progress_file.exists():
                self.progress_file.unlink()
        except Exception as e:
            print(f"  â†’ æ¸…é™¤è¿›åº¦å¤±è´¥: {e}")

    def estimate_total_pages(self) -> Optional[int]:
        """
        ä¼°ç®—æ€»é¡µæ•°

        Returns:
            int: ä¼°ç®—çš„æ€»é¡µæ•°ï¼Œå¤±è´¥è¿”å› None
        """
        try:
            # æŸ¥æ‰¾åˆ†é¡µæŒ‰é’®
            page_buttons = self.driver.find_elements(
                By.CSS_SELECTOR,
                'nav[aria-label="Pagination"] button, nav[aria-label="Pagination"] a'
            )

            # è·å–æ‰€æœ‰é¡µç æ•°å­—
            page_numbers = []
            for button in page_buttons:
                text = button.text.strip()
                if text.isdigit():
                    page_numbers.append(int(text))

            if page_numbers:
                return max(page_numbers)

            return None

        except Exception as e:
            print(f"  â†’ ä¼°ç®—æ€»é¡µæ•°å¤±è´¥: {e}")
            return None


def scrape_all_pages(
    driver,
    base_url: str,
    scrape_single_page_func,
    max_pages: Optional[int] = None,
    start_page: int = 1,
    enable_resume: bool = True
) -> List[Dict]:
    """
    çˆ¬å–æ‰€æœ‰åˆ†é¡µ

    Args:
        driver: WebDriver å®ä¾‹
        base_url: åŸºç¡€URL
        scrape_single_page_func: å•é¡µçˆ¬å–å‡½æ•°ï¼Œæ¥æ”¶ driver å’Œ url å‚æ•°
        max_pages: æœ€å¤§çˆ¬å–é¡µæ•°ï¼ŒNone è¡¨ç¤ºçˆ¬å–æ‰€æœ‰é¡µ
        start_page: èµ·å§‹é¡µç 
        enable_resume: æ˜¯å¦å¯ç”¨æ–­ç‚¹ç»­ä¼ 

    Returns:
        List[Dict]: æ‰€æœ‰äº§å“æ•°æ®
    """
    scraper = MultiPageScraper(driver)
    all_products = []
    current_page = start_page

    # å°è¯•åŠ è½½ä¹‹å‰çš„è¿›åº¦
    if enable_resume:
        progress = scraper.load_progress()
        if progress and progress.get("base_url") == base_url:
            print(f"\nğŸ“‚ å‘ç°ä¹‹å‰çš„è¿›åº¦:")
            print(f"   å·²çˆ¬å–: {progress.get('pages_scraped', 0)} é¡µ")
            print(f"   äº§å“æ•°: {progress.get('total_products', 0)} ä¸ª")
            response = input("æ˜¯å¦ç»§ç»­ä¹‹å‰çš„çˆ¬å–ï¼Ÿ(y/n): ").strip().lower()
            if response == "y":
                all_products = progress.get("products", [])
                current_page = progress.get("last_page", 1) + 1
                print(f"âœ“ ä»ç¬¬ {current_page} é¡µç»§ç»­çˆ¬å–")

    print(f"\n{'=' * 70}")
    print(f"å¼€å§‹å¤šé¡µçˆ¬å–")
    print(f"{'=' * 70}")
    print(f"èµ·å§‹é¡µ: {current_page}")
    print(f"æœ€å¤§é¡µæ•°: {max_pages or 'ä¸é™åˆ¶'}")
    print(f"{'=' * 70}")

    # æ„å»ºèµ·å§‹URL
    if current_page > 1:
        if "?" in base_url:
            url = f"{base_url}&page={current_page}"
        else:
            url = f"{base_url}?page={current_page}"
    else:
        url = base_url

    page_count = 0

    try:
        while True:
            # æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é¡µæ•°
            if max_pages and page_count >= max_pages:
                print(f"\nâ†’ å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({max_pages} é¡µ)")
                break

            print(f"\n{'=' * 70}")
            print(f"æ­£åœ¨çˆ¬å–ç¬¬ {current_page} é¡µ")
            print(f"{'=' * 70}")

            # çˆ¬å–å½“å‰é¡µ
            products = scrape_single_page_func(driver, url)

            if not products:
                print(f"âœ— ç¬¬ {current_page} é¡µæœªè·å–åˆ°äº§å“ï¼Œåœæ­¢çˆ¬å–")
                break

            all_products.extend(products)
            page_count += 1

            print(f"âœ“ ç¬¬ {current_page} é¡µçˆ¬å–å®Œæˆï¼Œè·å¾— {len(products)} ä¸ªäº§å“")
            print(f"âœ“ ç´¯è®¡: {len(all_products)} ä¸ªäº§å“")

            # ä¿å­˜è¿›åº¦
            if enable_resume:
                scraper.save_progress({
                    "base_url": base_url,
                    "last_page": current_page,
                    "pages_scraped": page_count,
                    "total_products": len(all_products),
                    "products": all_products,
                    "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
                })

            # å°è¯•è·³è½¬åˆ°ä¸‹ä¸€é¡µ
            if not scraper.go_to_next_page():
                print(f"\nâ†’ æ²¡æœ‰æ›´å¤šé¡µé¢äº†")
                break

            current_page += 1
            url = driver.current_url  # ä½¿ç”¨å½“å‰URL

            # ç¨å¾®å»¶è¿Ÿï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            time.sleep(2)

    except KeyboardInterrupt:
        print(f"\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­çˆ¬å–")
        print(f"âœ“ å·²ä¿å­˜è¿›åº¦ï¼Œä¸‹æ¬¡å¯ç»§ç»­")
        print(f"âœ“ å·²çˆ¬å– {page_count} é¡µï¼Œå…± {len(all_products)} ä¸ªäº§å“")

    # æ¸…é™¤è¿›åº¦æ–‡ä»¶ï¼ˆå¦‚æœæ­£å¸¸å®Œæˆï¼‰
    if enable_resume:
        scraper.clear_progress()

    print(f"\n{'=' * 70}")
    print(f"å¤šé¡µçˆ¬å–å®Œæˆ")
    print(f"{'=' * 70}")
    print(f"æ€»é¡µæ•°: {page_count}")
    print(f"æ€»äº§å“: {len(all_products)}")
    print(f"{'=' * 70}")

    return all_products
