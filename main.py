from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import csv
import os
import json
import re
from bs4 import BeautifulSoup
from typing import Dict, List, Any, Optional
from utils.translate import translate_main
from scripts.process_csv_images import image_post_precessor
from utils.multi_page_scraper import scrape_all_pages
from utils.parallel_scraper import scrape_details_parallel
from utils.logger import setup_logger, get_logger
import logging
import config


def handle_cookie_popup(driver, timeout=None):
    """ä¼˜é›…åœ°å¤„ç† Cookie å¼¹çª—"""
    logger = get_logger()
    if timeout is None:
        timeout = config.COOKIE_TIMEOUT
    try:
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ Cookie é€‰æ‹©å™¨
        selectors = config.COOKIE_SELECTORS

        for selector in selectors:
            try:
                button = WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((By.XPATH, selector)))
                button.click()
                print("âœ“ å·²æ¥å— Cookie")
                time.sleep(1)
                return True
            except:
                continue

        print("â†’ æœªå‘ç° Cookie å¼¹çª—")
        return False
    except Exception as e:
        print(f"â†’ Cookie å¤„ç†è·³è¿‡: {type(e).__name__}")
        return False


def scrape_product_list(driver, url):
    """çˆ¬å–äº§å“åˆ—è¡¨é¡µé¢çš„åŸºæœ¬ä¿¡æ¯"""
    print(f"\næ­£åœ¨è®¿é—®åˆ—è¡¨é¡µ: {url}")
    driver.get(url)

    # ç­‰å¾…é¡µé¢åŠ è½½
    time.sleep(3)

    # å¤„ç† Cookie å¼¹çª—
    handle_cookie_popup(driver)

    # ç­‰å¾…äº§å“å¡ç‰‡åŠ è½½
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test="product-card"]'))
        )
        print("âœ“ äº§å“åˆ—è¡¨å·²åŠ è½½")
    except:
        print("âœ— æœªæ‰¾åˆ°äº§å“å¡ç‰‡")
        return []

    # æ‰¾åˆ°æ‰€æœ‰äº§å“å¡ç‰‡
    product_cards = driver.find_elements(By.CSS_SELECTOR, '[data-test="product-card"]')
    print(f"âœ“ æ‰¾åˆ° {len(product_cards)} ä¸ªäº§å“")

    products = []

    for idx, card in enumerate(product_cards, 1):
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            product = {}

            # äº§å“é“¾æ¥
            product["url"] = card.get_attribute("href")

            # äº§å“å“ç‰Œ
            try:
                brand_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-card-brand-name"]')
                product["brand"] = brand_element.text.strip()
            except:
                product["brand"] = ""

            # äº§å“åç§°
            try:
                title_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-card-title"]')
                product["name"] = title_element.text.strip()
            except:
                product["name"] = ""

            # äº§å“ä»·æ ¼
            try:
                price_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-card-price"]')
                product["price"] = price_element.text.strip()
            except:
                product["price"] = ""

            # äº§å“å›¾ç‰‡
            try:
                image_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-image"]')
                product["image"] = image_element.get_attribute("src")
            except:
                product["image"] = ""

            products.append(product)
            print(f"  [{idx}] {product['brand']} - {product['name'][:50]}...")

        except Exception as e:
            print(f"  âœ— äº§å“ {idx} æå–å¤±è´¥: {e}")
            continue

    return products


def find_product_uuid(widgets: List[Dict]) -> Optional[str]:
    """é€’å½’æŸ¥æ‰¾äº§å“æ•°æ®çš„UUID"""
    for widget in widgets:
        if widget.get("name") == "accordions":
            refs = widget.get("resolveParamRefs", {})
            for key, uuid in refs.items():
                if "pdp_product_data" in key:
                    return uuid
        if "children" in widget and widget["children"]:
            uuid = find_product_uuid(widget["children"])
            if uuid:
                return uuid
    return None


def clean_html(html_text: str) -> str:
    """æ¸…ç†HTMLæ ‡ç­¾ï¼Œè¿”å›çº¯æ–‡æœ¬"""
    if not html_text:
        return ""
    soup = BeautifulSoup(html_text, "html.parser")
    return soup.get_text(strip=True, separator=" ")


def extract_product_json(html_content: str) -> Dict[str, Any]:
    """ä»HTMLä¸­æå–äº§å“JSONæ•°æ®"""
    # æå–JSONæ•°æ®
    match = re.search(r'<script id="__LAYOUT__"[^>]*>(.*?)</script>', html_content, re.DOTALL)

    if not match:
        print("  âœ— æœªæ‰¾åˆ°__LAYOUT__æ•°æ®")
        return {}

    try:
        layout_data = json.loads(match.group(1))
    except json.JSONDecodeError as e:
        print(f"  âœ— JSONè§£æå¤±è´¥: {e}")
        return {}

    # æŸ¥æ‰¾äº§å“æ•°æ®UUID
    product_uuid = find_product_uuid(layout_data.get("widgets", []))
    if not product_uuid:
        print("  âœ— æœªæ‰¾åˆ°äº§å“UUID")
        return {}

    # è·å–äº§å“æ•°æ®
    resolve_values = layout_data.get("resolveParamValues", {})
    if product_uuid not in resolve_values:
        print(f"  âœ— UUID {product_uuid} æœªæ‰¾åˆ°")
        return {}

    product_wrapper = resolve_values[product_uuid]
    if "data" not in product_wrapper:
        print("  âœ— äº§å“æ•°æ®æ ¼å¼é”™è¯¯")
        return {}

    return product_wrapper["data"]


def scrape_product_detail(driver, url):
    """çˆ¬å–äº§å“è¯¦æƒ…é¡µçš„è¯¦ç»†ä¿¡æ¯"""
    try:
        driver.get(url)

        # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
        time.sleep(4)

        # ç­‰å¾…é¡µé¢å…³é”®å…ƒç´ åŠ è½½
        try:
            WebDriverWait(driver, 10).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
        except:
            pass  # è¶…æ—¶ä¹Ÿç»§ç»­å°è¯•

        # è·å–é¡µé¢HTML
        html_content = driver.page_source

        # æå–JSONæ•°æ®
        product_data = extract_product_json(html_content)

        if not product_data:
            return {}

        details = {}

        # äº§å“äº®ç‚¹
        benefits = product_data.get("benefits", [])
        details["highlights"] = "; ".join(benefits) if benefits else ""

        # äº§å“æè¿°
        description_html = product_data.get("description", "")
        details["description"] = clean_html(description_html)

        # Info Sections
        info_sections = product_data.get("infoSections", {})
        info_section = info_sections.get("infoSection", {})

        # ç”¨æ³•è¯´æ˜
        directions = info_section.get("directions", {})
        heading = directions.get("heading", "")
        text = directions.get("text", "")
        details["directions"] = f"{heading} {text}".strip()

        # é…æ–™è¡¨
        ingredients = info_section.get("otherIngredients", {})
        ingredients_html = ingredients.get("text", "")
        details["ingredients"] = clean_html(ingredients_html)

        # è¥å…»æˆåˆ†
        nutritionals = info_sections.get("nutritionals", [])
        nutritional_text = []
        for nutritional in nutritionals:
            for section in nutritional.get("sections", []):
                fact = section.get("fact", {})
                for item in fact.get("keys", []):
                    nutrient = item.get("key", "").strip()
                    amount = item.get("value", "").strip()
                    if nutrient and amount:
                        nutritional_text.append(f"{nutrient}: {amount}")
        details["nutritional_info"] = "; ".join(nutritional_text)

        # ä½œç”¨éƒ¨ä½ï¼ˆä»CSVæ¨¡æ¿æ¥çœ‹éœ€è¦è¿™äº›å­—æ®µï¼Œä½†JSONä¸­å¯èƒ½æ²¡æœ‰ç›´æ¥å¯¹åº”ï¼‰
        # æš‚æ—¶ç•™ç©ºï¼Œåç»­å¯ä»¥æ ¹æ®å®é™…éœ€è¦è¡¥å……
        details["target_area"] = ""

        return details

    except Exception as e:
        print(f"  âœ— è¯¦æƒ…æå–å¤±è´¥: {e}")
        return {}


def main():
    print("=" * 60)
    print("Holland & Barrett äº§å“çˆ¬è™«")
    print("=" * 60)

    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„ Chrome é€‰é¡¹
    options = config.get_chrome_options()

    # ä½¿ç”¨ webdriver_manager è‡ªåŠ¨ç®¡ç† ChromeDriver
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¶…æ—¶è®¾ç½®
    driver.set_page_load_timeout(config.PAGE_LOAD_TIMEOUT)
    driver.set_script_timeout(config.SCRIPT_TIMEOUT)

    try:
        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤URL
        list_url = config.DEFAULT_CATEGORY_URL
        product_type = config.get_product_type_from_url(list_url)

        # çˆ¬å–æ¨¡å¼é€‰æ‹© - æ”¯æŒäº¤äº’å¼å’Œéäº¤äº’å¼
        if config.INTERACTIVE_MODE:
            print("\nçˆ¬å–æ¨¡å¼:")
            print("  1. å•é¡µæ¨¡å¼ - ä»…çˆ¬å–ç¬¬ä¸€é¡µï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰")
            print("  2. å¤šé¡µæ¨¡å¼ - çˆ¬å–æ‰€æœ‰é¡µé¢ï¼ˆå®Œæ•´æ•°æ®ï¼‰")
            print("  3. é™åˆ¶é¡µæ•° - çˆ¬å–æŒ‡å®šé¡µæ•°")
            mode = input("\né€‰æ‹©æ¨¡å¼ (1/2/3, é»˜è®¤1): ").strip() or "1"
        else:
            mode = str(config.SCRAPE_MODE)
            print(f"\nä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„çˆ¬å–æ¨¡å¼: {mode}")

        if mode == "1":
            # å•é¡µæ¨¡å¼
            print("  â†’ å•é¡µæ¨¡å¼")
            products = scrape_product_list(driver, list_url)
        elif mode == "2":
            # å¤šé¡µæ¨¡å¼ - çˆ¬å–æ‰€æœ‰é¡µ
            print("  â†’ å¤šé¡µæ¨¡å¼ - çˆ¬å–æ‰€æœ‰é¡µé¢")
            products = scrape_all_pages(
                driver=driver,
                base_url=list_url,
                scrape_single_page_func=scrape_product_list,
                max_pages=None,
                enable_resume=config.ENABLE_RESUME
            )
        elif mode == "3":
            # é™åˆ¶é¡µæ•°æ¨¡å¼
            if config.INTERACTIVE_MODE:
                try:
                    max_pages = int(input("è¦çˆ¬å–å¤šå°‘é¡µï¼Ÿ: ").strip())
                except ValueError:
                    print("è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨é…ç½®æ–‡ä»¶é»˜è®¤å€¼")
                    max_pages = config.MAX_PAGES_LIMIT
            else:
                max_pages = config.MAX_PAGES_LIMIT

            print(f"  â†’ é™åˆ¶é¡µæ•°æ¨¡å¼ - çˆ¬å–{max_pages}é¡µ")
            products = scrape_all_pages(
                driver=driver,
                base_url=list_url,
                scrape_single_page_func=scrape_product_list,
                max_pages=max_pages,
                enable_resume=config.ENABLE_RESUME
            )
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨å•é¡µæ¨¡å¼")
            products = scrape_product_list(driver, list_url)

        print(f"\n{'=' * 60}")
        print(f"å…±çˆ¬å– {len(products)} ä¸ªäº§å“çš„åŸºæœ¬ä¿¡æ¯")
        print(f"{'=' * 60}")

        # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è¾“å‡ºè·¯å¾„
        output_file = config.get_output_path(output_type='basic')
        if products:
            with open(output_file, "w", newline="", encoding="utf-8-sig") as f:
                writer = csv.DictWriter(f, fieldnames=config.CSV_FIELDNAMES_BASIC)
                writer.writeheader()
                writer.writerows(products)
            print(f"\nâœ“ åŸºæœ¬ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")

        # è¯¢é—®æ˜¯å¦ç»§ç»­çˆ¬å–è¯¦æƒ…é¡µ - æ”¯æŒäº¤äº’å¼å’Œéäº¤äº’å¼
        if config.INTERACTIVE_MODE:
            print("\nä¸‹ä¸€æ­¥: çˆ¬å–äº§å“è¯¦æƒ…é¡µï¼ˆéœ€è¦æ›´å¤šæ—¶é—´ï¼‰")
            print("æç¤º: è¯¦æƒ…é¡µçˆ¬å–ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å…ˆæµ‹è¯•å‡ ä¸ªäº§å“")
            response = input("æ˜¯å¦ç»§ç»­çˆ¬å–è¯¦æƒ…é¡µï¼Ÿ(y/n): ")
            scrape_details = response.lower() == "y"
        else:
            scrape_details = config.SCRAPE_DETAILS
            if scrape_details:
                print("\né…ç½®æ–‡ä»¶è®¾ç½®: çˆ¬å–è¯¦æƒ…é¡µ")
            else:
                print("\né…ç½®æ–‡ä»¶è®¾ç½®: è·³è¿‡è¯¦æƒ…é¡µçˆ¬å–")

        if scrape_details:
            # è¯¢é—®çˆ¬å–æ•°é‡ - æ”¯æŒäº¤äº’å¼å’Œéäº¤äº’å¼
            if config.INTERACTIVE_MODE:
                try:
                    max_count = input(f"è¦çˆ¬å–å¤šå°‘ä¸ªäº§å“ï¼Ÿ(1-{len(products)}, å›è½¦é»˜è®¤å…¨éƒ¨): ").strip()
                    if max_count:
                        max_products = min(int(max_count), len(products))
                    else:
                        max_products = len(products)
                except ValueError:
                    max_products = len(products)
            else:
                if config.MAX_PRODUCTS_TO_SCRAPE is not None:
                    max_products = min(config.MAX_PRODUCTS_TO_SCRAPE, len(products))
                    print(f"é…ç½®æ–‡ä»¶è®¾ç½®: çˆ¬å–{max_products}ä¸ªäº§å“")
                else:
                    max_products = len(products)
                    print(f"é…ç½®æ–‡ä»¶è®¾ç½®: çˆ¬å–å…¨éƒ¨{max_products}ä¸ªäº§å“")

            # è¯¢é—®æ˜¯å¦ä½¿ç”¨å¹¶è¡Œçˆ¬å– - æ”¯æŒäº¤äº’å¼å’Œéäº¤äº’å¼
            if config.INTERACTIVE_MODE:
                print("\nçˆ¬å–æ¨¡å¼:")
                print("  1. é¡ºåºæ¨¡å¼ - ä¸€ä¸ªæ¥ä¸€ä¸ªçˆ¬å–ï¼ˆè¾ƒæ…¢ä½†ç¨³å®šï¼‰")
                print("  2. å¹¶è¡Œæ¨¡å¼ - å¤šçº¿ç¨‹åŒæ—¶çˆ¬å–ï¼ˆæ¨èï¼Œ3-5ä¸ªçº¿ç¨‹ï¼‰")
                parallel_mode = input("é€‰æ‹©æ¨¡å¼ (1/2, é»˜è®¤2): ").strip() or "2"
            else:
                parallel_mode = str(config.DETAIL_SCRAPE_MODE)
                mode_name = "å¹¶è¡Œæ¨¡å¼" if parallel_mode == "2" else "é¡ºåºæ¨¡å¼"
                print(f"é…ç½®æ–‡ä»¶è®¾ç½®: {mode_name}")

            if parallel_mode == "2":
                # å¹¶è¡Œæ¨¡å¼é…ç½® - æ”¯æŒäº¤äº’å¼å’Œéäº¤äº’å¼
                if config.INTERACTIVE_MODE:
                    print(f"\næç¤º: å»ºè®®ä½¿ç”¨{config.DEFAULT_MAX_WORKERS}-5ä¸ªçº¿ç¨‹ä»¥å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§")
                    try:
                        workers = input(f"å¹¶å‘çº¿ç¨‹æ•° (å»ºè®®{config.DEFAULT_MAX_WORKERS}-5, é»˜è®¤{config.DEFAULT_MAX_WORKERS}): ").strip() or str(config.DEFAULT_MAX_WORKERS)
                        max_workers = min(max(int(workers), 1), config.MAX_WORKERS_LIMIT)
                    except ValueError:
                        max_workers = config.DEFAULT_MAX_WORKERS
                else:
                    max_workers = config.DEFAULT_MAX_WORKERS
                    print(f"é…ç½®æ–‡ä»¶è®¾ç½®: {max_workers}ä¸ªå¹¶å‘çº¿ç¨‹")

                retry_times = config.RETRY_TIMES
                request_delay = (config.REQUEST_DELAY_MIN, config.REQUEST_DELAY_MAX)

                print(f"\nä½¿ç”¨å¹¶è¡Œæ¨¡å¼çˆ¬å– {max_products} ä¸ªäº§å“ï¼Œ{max_workers} ä¸ªçº¿ç¨‹å¹¶å‘")
                print(f"é…ç½®: {retry_times}æ¬¡é‡è¯•, {request_delay[0]}-{request_delay[1]}ç§’éšæœºå»¶è¿Ÿ")
                print(f"ğŸ’¡ æ¯{config.BATCH_SIZE}ä¸ªäº§å“è‡ªåŠ¨å†™å…¥CSVï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤§")
                print(f"{'=' * 60}")

                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„å’Œå­—æ®µå
                final_output = config.get_output_path(output_type='complete')
                fieldnames = config.CSV_FIELDNAMES_COMPLETE

                # åˆ›å»ºæ‰¹æ¬¡å†™å…¥å›è°ƒå‡½æ•°
                def write_batch_to_csv(batch_products, batch_num):
                    """å°†æ‰¹æ¬¡äº§å“å†™å…¥CSV"""
                    from pathlib import Path
                    output_path = Path(final_output)
                    output_path.parent.mkdir(parents=True, exist_ok=True)

                    # ç¬¬ä¸€æ‰¹å†™å…¥æ—¶åŒ…å«è¡¨å¤´ï¼Œåç»­æ‰¹æ¬¡è¿½åŠ 
                    mode = 'w' if batch_num == 1 else 'a'
                    write_header = (batch_num == 1)

                    with open(output_path, mode, newline="", encoding="utf-8-sig") as f:
                        writer = csv.DictWriter(f, fieldnames=fieldnames)
                        if write_header:
                            writer.writeheader()

                        for product in batch_products:
                            row = {
                                "äº§å“åç§°": product.get("name", ""),
                                "äº§å“ä»·æ ¼": product.get("price", ""),
                                "äº§å“äº®ç‚¹": product.get("highlights", ""),
                                "ç”¨æ³•è¯´æ˜": product.get("directions", ""),
                                "äº§å“å›¾": product.get("image", ""),
                                "äº§å“ç±»å‹": product_type,
                                "ä½œç”¨éƒ¨ä½": product.get("target_area", ""),
                                "é…æ–™è¡¨": product.get("ingredients", ""),
                                "äº§å“å“ç‰Œ": product.get("brand", ""),
                                "äº§å“æè¿°": product.get("description", ""),
                                "è¥å…»æˆåˆ†": product.get("nutritional_info", ""),
                                "URL": product.get("url", ""),
                            }
                            writer.writerow(row)

                    print(f"âœ“ æ‰¹æ¬¡ {batch_num} å·²å†™å…¥ {len(batch_products)} ä¸ªäº§å“åˆ° {final_output}")

                # ä½¿ç”¨å¹¶è¡Œçˆ¬å–ï¼ˆå¸¦åˆ†æ‰¹å†™å…¥ï¼‰- ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„æ‰¹æ¬¡å¤§å°
                products = scrape_details_parallel(
                    products=products,
                    scrape_detail_func=scrape_product_detail,
                    max_workers=max_workers,
                    max_products=max_products,
                    retry_times=retry_times,
                    request_delay=request_delay,
                    batch_size=config.BATCH_SIZE,
                    batch_callback=write_batch_to_csv
                )
            else:
                # é¡ºåºçˆ¬å–ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
                print(f"\nä½¿ç”¨é¡ºåºæ¨¡å¼çˆ¬å– {max_products} ä¸ªäº§å“çš„è¯¦æƒ…...")
                print(f"{'=' * 60}")

                failed_products = []  # è®°å½•å¤±è´¥çš„äº§å“
                for idx, product in enumerate(products[:max_products], 1):
                    print(f"\n[{idx}/{max_products}] {product['name'][:50]}...")
                    try:
                        details = scrape_product_detail(driver, product["url"])
                        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–åˆ°è¯¦æƒ…
                        if details and any(key in details for key in ['highlights', 'description', 'directions']):
                            product.update(details)
                        else:
                            print(f"  âœ— æœªè·å–åˆ°è¯¦æƒ…æ•°æ®")
                            failed_products.append({
                                "item_data": product.copy(),
                                "error": "æœªè·å–åˆ°è¯¦æƒ…æ•°æ®",
                                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
                                "url": product["url"]
                            })
                    except Exception as e:
                        print(f"  âœ— çˆ¬å–å¤±è´¥: {e}")
                        failed_products.append({
                            "item_data": product.copy(),
                            "error": str(e),
                            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
                            "url": product["url"]
                        })
                    time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«

                # ä¿å­˜å¤±è´¥è®°å½• - ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„
                if failed_products:
                    import json
                    from pathlib import Path
                    failed_file = config.get_output_path(output_type='failed')
                    failed_file.parent.mkdir(parents=True, exist_ok=True)

                    # åŠ è½½ç°æœ‰å¤±è´¥è®°å½•
                    existing_failed = []
                    if failed_file.exists():
                        try:
                            with open(failed_file, 'r', encoding='utf-8') as f:
                                existing_failed = json.load(f)
                        except:
                            pass

                    # åˆå¹¶å¹¶ä¿å­˜
                    all_failed = existing_failed + failed_products
                    with open(failed_file, 'w', encoding='utf-8') as f:
                        json.dump(all_failed, f, ensure_ascii=False, indent=2)

                    print(f"\nâœ— {len(failed_products)} ä¸ªäº§å“çˆ¬å–å¤±è´¥ï¼Œå·²è®°å½•åˆ°: {failed_file}")
                    print(f"  å¯ä½¿ç”¨ 'uv run python scripts/retry_failed.py' é‡æ–°çˆ¬å–")

            # ä¿å­˜å®Œæ•´æ•°æ®åˆ°CSVï¼ˆå¦‚æœæ˜¯å¹¶è¡Œæ¨¡å¼ä¸”ä½¿ç”¨äº†åˆ†æ‰¹å†™å…¥ï¼Œåˆ™è·³è¿‡ï¼‰
            if parallel_mode != "2":  # é¡ºåºæ¨¡å¼éœ€è¦ä¿å­˜
                # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„å’Œå­—æ®µå
                final_output = config.get_output_path(output_type='complete')
                fieldnames = config.CSV_FIELDNAMES_COMPLETE

                with open(final_output, "w", newline="", encoding="utf-8-sig") as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()

                    for product in products[:max_products]:
                        row = {
                            "äº§å“åç§°": product.get("name", ""),
                            "äº§å“ä»·æ ¼": product.get("price", ""),
                            "äº§å“äº®ç‚¹": product.get("highlights", ""),
                            "ç”¨æ³•è¯´æ˜": product.get("directions", ""),
                            "äº§å“å›¾": product.get("image", ""),
                            "äº§å“ç±»å‹": product_type,
                            "ä½œç”¨éƒ¨ä½": product.get("target_area", ""),
                            "é…æ–™è¡¨": product.get("ingredients", ""),
                            "äº§å“å“ç‰Œ": product.get("brand", ""),
                            "äº§å“æè¿°": product.get("description", ""),
                            "è¥å…»æˆåˆ†": product.get("nutritional_info", ""),
                            "URL": product.get("url", ""),
                        }
                        writer.writerow(row)

            print(f"\n{'=' * 60}")
            if parallel_mode == "2":
                # å¹¶è¡Œæ¨¡å¼å·²ç»åˆ†æ‰¹ä¿å­˜
                print(f"âœ“ æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: data/output/products_complete.csv")
                print(f"âœ“ å…±çˆ¬å– {len(products)} ä¸ªäº§å“çš„å®Œæ•´ä¿¡æ¯")
            else:
                # é¡ºåºæ¨¡å¼æœ€åä¿å­˜
                print(f"âœ“ å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: data/output/products_complete.csv")
                print(f"âœ“ å…±çˆ¬å– {max_products} ä¸ªäº§å“çš„å®Œæ•´ä¿¡æ¯")
            print(f"{'=' * 60}")

        # è¿è¡Œç¿»è¯‘å’Œå›¾ç‰‡å¤„ç† - æ ¹æ®é…ç½®å†³å®š
        if config.RUN_TRANSLATION:
            print("\nè¿è¡Œç¿»è¯‘...")
            translate_main()
        else:
            print("\nè·³è¿‡ç¿»è¯‘ï¼ˆé…ç½®æ–‡ä»¶è®¾ç½®ï¼‰")

        if config.RUN_IMAGE_PROCESSING:
            print("\nè¿è¡Œå›¾ç‰‡å¤„ç†...")
            image_post_precessor()
        else:
            print("\nè·³è¿‡å›¾ç‰‡å¤„ç†ï¼ˆé…ç½®æ–‡ä»¶è®¾ç½®ï¼‰")
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­çˆ¬è™«")
    except Exception as e:
        print(f"\nâœ— å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        print("\nå…³é—­æµè§ˆå™¨...")
        driver.quit()
        print("å®Œæˆ!")


if __name__ == "__main__":
    main()
