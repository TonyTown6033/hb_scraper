from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
import time
import csv
import os
import json
import re
from bs4 import BeautifulSoup
from typing import Dict, List, Any, Optional
from utils.translate import translate_main
from scripts.process_csv_images import image_post_precessor
from utils.multi_page_scraper import scrape_all_pages
from utils.parallel_scraper import scrape_details_parallel
from utils.logger import setup_logger, get_logger
import logging


def handle_cookie_popup(driver, timeout=5):
    """ä¼˜é›…åœ°å¤„ç† Cookie å¼¹çª—"""
    logger = get_logger()
    try:
        # å°è¯•å¤šç§å¯èƒ½çš„ Cookie æ¥å—æŒ‰é’®é€‰æ‹©å™¨
        selectors = [
            "//button[contains(text(), 'Yes I Accept')]",
            "//button[contains(text(), 'Accept')]",
            "//button[@id='onetrust-accept-btn-handler']",
        ]

        for selector in selectors:
            try:
                button = WebDriverWait(driver, timeout).until(EC.element_to_be_clickable((By.XPATH, selector)))
                button.click()
                print("âœ“ å·²æ¥å— Cookie")
                time.sleep(1)
                return True
            except:
                continue

        print("â†’ æœªå‘ç° Cookie å¼¹çª—")
        return False
    except Exception as e:
        print(f"â†’ Cookie å¤„ç†è·³è¿‡: {type(e).__name__}")
        return False


def scrape_product_list(driver, url):
    """çˆ¬å–äº§å“åˆ—è¡¨é¡µé¢çš„åŸºæœ¬ä¿¡æ¯"""
    print(f"\næ­£åœ¨è®¿é—®åˆ—è¡¨é¡µ: {url}")
    driver.get(url)

    # ç­‰å¾…é¡µé¢åŠ è½½
    time.sleep(3)

    # å¤„ç† Cookie å¼¹çª—
    handle_cookie_popup(driver)

    # ç­‰å¾…äº§å“å¡ç‰‡åŠ è½½
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, '[data-test="product-card"]'))
        )
        print("âœ“ äº§å“åˆ—è¡¨å·²åŠ è½½")
    except:
        print("âœ— æœªæ‰¾åˆ°äº§å“å¡ç‰‡")
        return []

    # æ‰¾åˆ°æ‰€æœ‰äº§å“å¡ç‰‡
    product_cards = driver.find_elements(By.CSS_SELECTOR, '[data-test="product-card"]')
    print(f"âœ“ æ‰¾åˆ° {len(product_cards)} ä¸ªäº§å“")

    products = []

    for idx, card in enumerate(product_cards, 1):
        try:
            # æå–åŸºæœ¬ä¿¡æ¯
            product = {}

            # äº§å“é“¾æ¥
            product["url"] = card.get_attribute("href")

            # äº§å“å“ç‰Œ
            try:
                brand_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-card-brand-name"]')
                product["brand"] = brand_element.text.strip()
            except:
                product["brand"] = ""

            # äº§å“åç§°
            try:
                title_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-card-title"]')
                product["name"] = title_element.text.strip()
            except:
                product["name"] = ""

            # äº§å“ä»·æ ¼
            try:
                price_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-card-price"]')
                product["price"] = price_element.text.strip()
            except:
                product["price"] = ""

            # äº§å“å›¾ç‰‡
            try:
                image_element = card.find_element(By.CSS_SELECTOR, '[data-test="product-image"]')
                product["image"] = image_element.get_attribute("src")
            except:
                product["image"] = ""

            products.append(product)
            print(f"  [{idx}] {product['brand']} - {product['name'][:50]}...")

        except Exception as e:
            print(f"  âœ— äº§å“ {idx} æå–å¤±è´¥: {e}")
            continue

    return products


def find_product_uuid(widgets: List[Dict]) -> Optional[str]:
    """é€’å½’æŸ¥æ‰¾äº§å“æ•°æ®çš„UUID"""
    for widget in widgets:
        if widget.get("name") == "accordions":
            refs = widget.get("resolveParamRefs", {})
            for key, uuid in refs.items():
                if "pdp_product_data" in key:
                    return uuid
        if "children" in widget and widget["children"]:
            uuid = find_product_uuid(widget["children"])
            if uuid:
                return uuid
    return None


def clean_html(html_text: str) -> str:
    """æ¸…ç†HTMLæ ‡ç­¾ï¼Œè¿”å›çº¯æ–‡æœ¬"""
    if not html_text:
        return ""
    soup = BeautifulSoup(html_text, "html.parser")
    return soup.get_text(strip=True, separator=" ")


def extract_product_json(html_content: str) -> Dict[str, Any]:
    """ä»HTMLä¸­æå–äº§å“JSONæ•°æ®"""
    # æå–JSONæ•°æ®
    match = re.search(r'<script id="__LAYOUT__"[^>]*>(.*?)</script>', html_content, re.DOTALL)

    if not match:
        print("  âœ— æœªæ‰¾åˆ°__LAYOUT__æ•°æ®")
        return {}

    try:
        layout_data = json.loads(match.group(1))
    except json.JSONDecodeError as e:
        print(f"  âœ— JSONè§£æå¤±è´¥: {e}")
        return {}

    # æŸ¥æ‰¾äº§å“æ•°æ®UUID
    product_uuid = find_product_uuid(layout_data.get("widgets", []))
    if not product_uuid:
        print("  âœ— æœªæ‰¾åˆ°äº§å“UUID")
        return {}

    # è·å–äº§å“æ•°æ®
    resolve_values = layout_data.get("resolveParamValues", {})
    if product_uuid not in resolve_values:
        print(f"  âœ— UUID {product_uuid} æœªæ‰¾åˆ°")
        return {}

    product_wrapper = resolve_values[product_uuid]
    if "data" not in product_wrapper:
        print("  âœ— äº§å“æ•°æ®æ ¼å¼é”™è¯¯")
        return {}

    return product_wrapper["data"]


def scrape_product_detail(driver, url):
    """çˆ¬å–äº§å“è¯¦æƒ…é¡µçš„è¯¦ç»†ä¿¡æ¯"""
    try:
        driver.get(url)

        # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
        time.sleep(4)

        # ç­‰å¾…é¡µé¢å…³é”®å…ƒç´ åŠ è½½
        try:
            WebDriverWait(driver, 10).until(
                lambda d: d.execute_script("return document.readyState") == "complete"
            )
        except:
            pass  # è¶…æ—¶ä¹Ÿç»§ç»­å°è¯•

        # è·å–é¡µé¢HTML
        html_content = driver.page_source

        # æå–JSONæ•°æ®
        product_data = extract_product_json(html_content)

        if not product_data:
            return {}

        details = {}

        # äº§å“äº®ç‚¹
        benefits = product_data.get("benefits", [])
        details["highlights"] = "; ".join(benefits) if benefits else ""

        # äº§å“æè¿°
        description_html = product_data.get("description", "")
        details["description"] = clean_html(description_html)

        # Info Sections
        info_sections = product_data.get("infoSections", {})
        info_section = info_sections.get("infoSection", {})

        # ç”¨æ³•è¯´æ˜
        directions = info_section.get("directions", {})
        heading = directions.get("heading", "")
        text = directions.get("text", "")
        details["directions"] = f"{heading} {text}".strip()

        # é…æ–™è¡¨
        ingredients = info_section.get("otherIngredients", {})
        ingredients_html = ingredients.get("text", "")
        details["ingredients"] = clean_html(ingredients_html)

        # è¥å…»æˆåˆ†
        nutritionals = info_sections.get("nutritionals", [])
        nutritional_text = []
        for nutritional in nutritionals:
            for section in nutritional.get("sections", []):
                fact = section.get("fact", {})
                for item in fact.get("keys", []):
                    nutrient = item.get("key", "").strip()
                    amount = item.get("value", "").strip()
                    if nutrient and amount:
                        nutritional_text.append(f"{nutrient}: {amount}")
        details["nutritional_info"] = "; ".join(nutritional_text)

        # ä½œç”¨éƒ¨ä½ï¼ˆä»CSVæ¨¡æ¿æ¥çœ‹éœ€è¦è¿™äº›å­—æ®µï¼Œä½†JSONä¸­å¯èƒ½æ²¡æœ‰ç›´æ¥å¯¹åº”ï¼‰
        # æš‚æ—¶ç•™ç©ºï¼Œåç»­å¯ä»¥æ ¹æ®å®é™…éœ€è¦è¡¥å……
        details["target_area"] = ""

        return details

    except Exception as e:
        print(f"  âœ— è¯¦æƒ…æå–å¤±è´¥: {e}")
        return {}


def main():
    print("=" * 60)
    print("Holland & Barrett äº§å“çˆ¬è™«")
    print("=" * 60)

    # é…ç½® Chrome é€‰é¡¹
    options = webdriver.ChromeOptions()
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)

    # ä½¿ç”¨ webdriver_manager è‡ªåŠ¨ç®¡ç† ChromeDriver
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=options)

    try:
        # çˆ¬å–äº§å“åˆ—è¡¨
        list_url = "https://www.hollandandbarrett.com/shop/vitamins-supplements/condition/hair-skin-nails/"
        product_type = list_url.split("/shop/")[1].split("/")[0]

        # è¯¢é—®çˆ¬å–æ¨¡å¼
        print("\nçˆ¬å–æ¨¡å¼:")
        print("  1. å•é¡µæ¨¡å¼ - ä»…çˆ¬å–ç¬¬ä¸€é¡µï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰")
        print("  2. å¤šé¡µæ¨¡å¼ - çˆ¬å–æ‰€æœ‰é¡µé¢ï¼ˆå®Œæ•´æ•°æ®ï¼‰")
        print("  3. é™åˆ¶é¡µæ•° - çˆ¬å–æŒ‡å®šé¡µæ•°")

        mode = input("\né€‰æ‹©æ¨¡å¼ (1/2/3, é»˜è®¤1): ").strip() or "1"

        if mode == "1":
            # å•é¡µæ¨¡å¼
            products = scrape_product_list(driver, list_url)
        elif mode == "2":
            # å¤šé¡µæ¨¡å¼ - çˆ¬å–æ‰€æœ‰é¡µ
            products = scrape_all_pages(
                driver=driver,
                base_url=list_url,
                scrape_single_page_func=scrape_product_list,
                max_pages=None,
                enable_resume=True
            )
        elif mode == "3":
            # é™åˆ¶é¡µæ•°æ¨¡å¼
            try:
                max_pages = int(input("è¦çˆ¬å–å¤šå°‘é¡µï¼Ÿ: ").strip())
                products = scrape_all_pages(
                    driver=driver,
                    base_url=list_url,
                    scrape_single_page_func=scrape_product_list,
                    max_pages=max_pages,
                    enable_resume=True
                )
            except ValueError:
                print("è¾“å…¥æ— æ•ˆï¼Œä½¿ç”¨å•é¡µæ¨¡å¼")
                products = scrape_product_list(driver, list_url)
        else:
            print("æ— æ•ˆé€‰æ‹©ï¼Œä½¿ç”¨å•é¡µæ¨¡å¼")
            products = scrape_product_list(driver, list_url)

        print(f"\n{'=' * 60}")
        print(f"å…±çˆ¬å– {len(products)} ä¸ªäº§å“çš„åŸºæœ¬ä¿¡æ¯")
        print(f"{'=' * 60}")

        # ä¿å­˜åŸºæœ¬ä¿¡æ¯åˆ°CSVï¼ˆæš‚æ—¶ä¸åŒ…å«è¯¦æƒ…ï¼‰
        output_file = "data/output/products_basic.csv"
        if products:
            with open(output_file, "w", newline="", encoding="utf-8-sig") as f:
                writer = csv.DictWriter(f, fieldnames=["brand", "name", "price", "image", "url"])
                writer.writeheader()
                writer.writerows(products)
            print(f"\nâœ“ åŸºæœ¬ä¿¡æ¯å·²ä¿å­˜åˆ°: {output_file}")

        # è¯¢é—®æ˜¯å¦ç»§ç»­çˆ¬å–è¯¦æƒ…é¡µ
        print("\nä¸‹ä¸€æ­¥: çˆ¬å–äº§å“è¯¦æƒ…é¡µï¼ˆéœ€è¦æ›´å¤šæ—¶é—´ï¼‰")
        print("æç¤º: è¯¦æƒ…é¡µçˆ¬å–ä¼šèŠ±è´¹è¾ƒé•¿æ—¶é—´ï¼Œå»ºè®®å…ˆæµ‹è¯•å‡ ä¸ªäº§å“")
        response = input("æ˜¯å¦ç»§ç»­çˆ¬å–è¯¦æƒ…é¡µï¼Ÿ(y/n): ")

        if response.lower() == "y":
            # è¯¢é—®çˆ¬å–æ•°é‡
            try:
                max_count = input(f"è¦çˆ¬å–å¤šå°‘ä¸ªäº§å“ï¼Ÿ(1-{len(products)}, å›è½¦é»˜è®¤å…¨éƒ¨): ").strip()
                if max_count:
                    max_products = min(int(max_count), len(products))
                else:
                    max_products = len(products)
            except ValueError:
                max_products = len(products)

            # è¯¢é—®æ˜¯å¦ä½¿ç”¨å¹¶è¡Œçˆ¬å–
            print("\nçˆ¬å–æ¨¡å¼:")
            print("  1. é¡ºåºæ¨¡å¼ - ä¸€ä¸ªæ¥ä¸€ä¸ªçˆ¬å–ï¼ˆè¾ƒæ…¢ä½†ç¨³å®šï¼‰")
            print("  2. å¹¶è¡Œæ¨¡å¼ - å¤šçº¿ç¨‹åŒæ—¶çˆ¬å–ï¼ˆæ¨èï¼Œ3-5ä¸ªçº¿ç¨‹ï¼‰")
            parallel_mode = input("é€‰æ‹©æ¨¡å¼ (1/2, é»˜è®¤2): ").strip() or "2"

            if parallel_mode == "2":
                # å¹¶è¡Œæ¨¡å¼é…ç½®
                print("\næç¤º: å»ºè®®ä½¿ç”¨3-5ä¸ªçº¿ç¨‹ä»¥å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§")
                try:
                    workers = input("å¹¶å‘çº¿ç¨‹æ•° (å»ºè®®3-5, é»˜è®¤3): ").strip() or "3"
                    max_workers = min(max(int(workers), 1), 10)  # é™åˆ¶åœ¨1-10ä¹‹é—´
                except ValueError:
                    max_workers = 3

                retry_times = 3
                request_delay = (2, 4)

                print(f"\nä½¿ç”¨å¹¶è¡Œæ¨¡å¼çˆ¬å– {max_products} ä¸ªäº§å“ï¼Œ{max_workers} ä¸ªçº¿ç¨‹å¹¶å‘")
                print(f"é…ç½®: {retry_times}æ¬¡é‡è¯•, {request_delay[0]}-{request_delay[1]}ç§’éšæœºå»¶è¿Ÿ")
                print(f"ğŸ’¡ æ¯100ä¸ªäº§å“è‡ªåŠ¨å†™å…¥CSVï¼Œé¿å…å†…å­˜å ç”¨è¿‡å¤§")
                print(f"{'=' * 60}")

                # å®šä¹‰CSVæ–‡ä»¶è·¯å¾„
                final_output = "data/output/products_complete.csv"
                fieldnames = [
                    "äº§å“åç§°", "äº§å“äº®ç‚¹", "äº§å“ä»·æ ¼", "äº§å“å“ç‰Œ",
                    "äº§å“å›¾", "äº§å“æè¿°", "äº§å“ç±»å‹", "ä½œç”¨éƒ¨ä½",
                    "ç”¨æ³•è¯´æ˜", "è¥å…»æˆåˆ†", "é…æ–™è¡¨", "URL"
                ]

                # åˆ›å»ºæ‰¹æ¬¡å†™å…¥å›è°ƒå‡½æ•°
                def write_batch_to_csv(batch_products, batch_num):
                    """å°†æ‰¹æ¬¡äº§å“å†™å…¥CSV"""
                    from pathlib import Path
                    output_path = Path(final_output)
                    output_path.parent.mkdir(parents=True, exist_ok=True)

                    # ç¬¬ä¸€æ‰¹å†™å…¥æ—¶åŒ…å«è¡¨å¤´ï¼Œåç»­æ‰¹æ¬¡è¿½åŠ 
                    mode = 'w' if batch_num == 1 else 'a'
                    write_header = (batch_num == 1)

                    with open(output_path, mode, newline="", encoding="utf-8-sig") as f:
                        writer = csv.DictWriter(f, fieldnames=fieldnames)
                        if write_header:
                            writer.writeheader()

                        for product in batch_products:
                            row = {
                                "äº§å“åç§°": product.get("name", ""),
                                "äº§å“ä»·æ ¼": product.get("price", ""),
                                "äº§å“äº®ç‚¹": product.get("highlights", ""),
                                "ç”¨æ³•è¯´æ˜": product.get("directions", ""),
                                "äº§å“å›¾": product.get("image", ""),
                                "äº§å“ç±»å‹": product_type,
                                "ä½œç”¨éƒ¨ä½": product.get("target_area", ""),
                                "é…æ–™è¡¨": product.get("ingredients", ""),
                                "äº§å“å“ç‰Œ": product.get("brand", ""),
                                "äº§å“æè¿°": product.get("description", ""),
                                "è¥å…»æˆåˆ†": product.get("nutritional_info", ""),
                                "URL": product.get("url", ""),
                            }
                            writer.writerow(row)

                    print(f"âœ“ æ‰¹æ¬¡ {batch_num} å·²å†™å…¥ {len(batch_products)} ä¸ªäº§å“åˆ° {final_output}")

                # ä½¿ç”¨å¹¶è¡Œçˆ¬å–ï¼ˆå¸¦åˆ†æ‰¹å†™å…¥ï¼‰
                products = scrape_details_parallel(
                    products=products,
                    scrape_detail_func=scrape_product_detail,
                    max_workers=max_workers,
                    max_products=max_products,
                    retry_times=retry_times,
                    request_delay=request_delay,
                    batch_size=100,  # æ¯100ä¸ªäº§å“å†™å…¥ä¸€æ¬¡
                    batch_callback=write_batch_to_csv
                )
            else:
                # é¡ºåºçˆ¬å–ï¼ˆä¿ç•™åŸæœ‰é€»è¾‘ï¼‰
                print(f"\nä½¿ç”¨é¡ºåºæ¨¡å¼çˆ¬å– {max_products} ä¸ªäº§å“çš„è¯¦æƒ…...")
                print(f"{'=' * 60}")

                failed_products = []  # è®°å½•å¤±è´¥çš„äº§å“
                for idx, product in enumerate(products[:max_products], 1):
                    print(f"\n[{idx}/{max_products}] {product['name'][:50]}...")
                    try:
                        details = scrape_product_detail(driver, product["url"])
                        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–åˆ°è¯¦æƒ…
                        if details and any(key in details for key in ['highlights', 'description', 'directions']):
                            product.update(details)
                        else:
                            print(f"  âœ— æœªè·å–åˆ°è¯¦æƒ…æ•°æ®")
                            failed_products.append({
                                "item_data": product.copy(),
                                "error": "æœªè·å–åˆ°è¯¦æƒ…æ•°æ®",
                                "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
                                "url": product["url"]
                            })
                    except Exception as e:
                        print(f"  âœ— çˆ¬å–å¤±è´¥: {e}")
                        failed_products.append({
                            "item_data": product.copy(),
                            "error": str(e),
                            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%S"),
                            "url": product["url"]
                        })
                    time.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«

                # ä¿å­˜å¤±è´¥è®°å½•
                if failed_products:
                    import json
                    from pathlib import Path
                    failed_file = Path("data/output/failed_products.json")
                    failed_file.parent.mkdir(parents=True, exist_ok=True)

                    # åŠ è½½ç°æœ‰å¤±è´¥è®°å½•
                    existing_failed = []
                    if failed_file.exists():
                        try:
                            with open(failed_file, 'r', encoding='utf-8') as f:
                                existing_failed = json.load(f)
                        except:
                            pass

                    # åˆå¹¶å¹¶ä¿å­˜
                    all_failed = existing_failed + failed_products
                    with open(failed_file, 'w', encoding='utf-8') as f:
                        json.dump(all_failed, f, ensure_ascii=False, indent=2)

                    print(f"\nâœ— {len(failed_products)} ä¸ªäº§å“çˆ¬å–å¤±è´¥ï¼Œå·²è®°å½•åˆ°: {failed_file}")
                    print(f"  å¯ä½¿ç”¨ 'uv run python scripts/retry_failed.py' é‡æ–°çˆ¬å–")

            # ä¿å­˜å®Œæ•´æ•°æ®åˆ°CSVï¼ˆå¦‚æœæ˜¯å¹¶è¡Œæ¨¡å¼ä¸”ä½¿ç”¨äº†åˆ†æ‰¹å†™å…¥ï¼Œåˆ™è·³è¿‡ï¼‰
            if parallel_mode != "2":  # é¡ºåºæ¨¡å¼éœ€è¦ä¿å­˜
                final_output = "data/output/products_complete.csv"
                fieldnames = [
                    "äº§å“åç§°",
                    "äº§å“äº®ç‚¹",
                    "äº§å“ä»·æ ¼",
                    "äº§å“å“ç‰Œ",
                    "äº§å“å›¾",
                    "äº§å“æè¿°",
                    "äº§å“ç±»å‹",
                    "ä½œç”¨éƒ¨ä½",
                    "ç”¨æ³•è¯´æ˜",
                    "è¥å…»æˆåˆ†",
                    "é…æ–™è¡¨",
                    "URL",
                ]

                with open(final_output, "w", newline="", encoding="utf-8-sig") as f:
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()

                    for product in products[:max_products]:
                        row = {
                            "äº§å“åç§°": product.get("name", ""),
                            "äº§å“ä»·æ ¼": product.get("price", ""),
                            "äº§å“äº®ç‚¹": product.get("highlights", ""),
                            "ç”¨æ³•è¯´æ˜": product.get("directions", ""),
                            "äº§å“å›¾": product.get("image", ""),
                            "äº§å“ç±»å‹": product_type,
                            "ä½œç”¨éƒ¨ä½": product.get("target_area", ""),
                            "é…æ–™è¡¨": product.get("ingredients", ""),
                            "äº§å“å“ç‰Œ": product.get("brand", ""),
                            "äº§å“æè¿°": product.get("description", ""),
                            "è¥å…»æˆåˆ†": product.get("nutritional_info", ""),
                            "URL": product.get("url", ""),
                        }
                        writer.writerow(row)

            print(f"\n{'=' * 60}")
            if parallel_mode == "2":
                # å¹¶è¡Œæ¨¡å¼å·²ç»åˆ†æ‰¹ä¿å­˜
                print(f"âœ“ æ‰€æœ‰æ•°æ®å·²ä¿å­˜åˆ°: data/output/products_complete.csv")
                print(f"âœ“ å…±çˆ¬å– {len(products)} ä¸ªäº§å“çš„å®Œæ•´ä¿¡æ¯")
            else:
                # é¡ºåºæ¨¡å¼æœ€åä¿å­˜
                print(f"âœ“ å®Œæ•´æ•°æ®å·²ä¿å­˜åˆ°: data/output/products_complete.csv")
                print(f"âœ“ å…±çˆ¬å– {max_products} ä¸ªäº§å“çš„å®Œæ•´ä¿¡æ¯")
            print(f"{'=' * 60}")

        translate_main()
        image_post_precessor()
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­çˆ¬è™«")
    except Exception as e:
        print(f"\nâœ— å‘ç”Ÿé”™è¯¯: {e}")
    finally:
        print("\nå…³é—­æµè§ˆå™¨...")
        driver.quit()
        print("å®Œæˆ!")


if __name__ == "__main__":
    main()
