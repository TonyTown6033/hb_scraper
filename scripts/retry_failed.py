#!/usr/bin/env python3
"""
é‡æ–°çˆ¬å–å¤±è´¥çš„äº§å“

ä½¿ç”¨æ–¹æ³•:
    uv run python scripts/retry_failed.py

åŠŸèƒ½:
    - è¯»å–å¤±è´¥è®°å½•æ–‡ä»¶
    - æ˜¾ç¤ºå¤±è´¥äº§å“åˆ—è¡¨
    - é‡æ–°çˆ¬å–å¤±è´¥çš„äº§å“
    - æ›´æ–°å¤±è´¥è®°å½•
"""

import sys
import json
import time
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from utils.parallel_scraper import scrape_details_parallel
from main import scrape_product_detail
from utils.logger import get_logger


def load_failed_products():
    """åŠ è½½å¤±è´¥çš„äº§å“è®°å½•"""
    failed_file = project_root / "data" / "output" / "failed_products.json"

    if not failed_file.exists():
        print("âœ“ æ²¡æœ‰å¤±è´¥çš„äº§å“è®°å½•")
        return []

    with open(failed_file, 'r', encoding='utf-8') as f:
        failed_products = json.load(f)

    return failed_products


def show_failed_summary(failed_products):
    """æ˜¾ç¤ºå¤±è´¥äº§å“æ‘˜è¦"""
    if not failed_products:
        return

    print(f"\n{'=' * 70}")
    print(f"å¤±è´¥äº§å“åˆ—è¡¨ (å…± {len(failed_products)} ä¸ª)")
    print(f"{'=' * 70}\n")

    # æŒ‰æ—¶é—´åˆ†ç»„ç»Ÿè®¡
    from collections import defaultdict
    by_date = defaultdict(list)
    for item in failed_products:
        timestamp = item.get('timestamp', '')
        date = timestamp.split('T')[0] if 'T' in timestamp else 'æœªçŸ¥æ—¥æœŸ'
        by_date[date].append(item)

    for date, items in sorted(by_date.items(), reverse=True):
        print(f"{date}: {len(items)} ä¸ªå¤±è´¥")

    print(f"\n{'=' * 70}")
    print("å¤±è´¥åŸå› ç»Ÿè®¡:")
    print(f"{'=' * 70}\n")

    # ç»Ÿè®¡å¤±è´¥åŸå› 
    error_types = defaultdict(int)
    for item in failed_products:
        error = item.get('error', 'Unknown')
        # ç®€åŒ–é”™è¯¯ä¿¡æ¯
        if 'Could not reach host' in error:
            error_type = 'ç½‘ç»œè¿æ¥å¤±è´¥'
        elif 'æœªæ‰¾åˆ°__LAYOUT__æ•°æ®' in error:
            error_type = 'é¡µé¢æ•°æ®æå–å¤±è´¥'
        elif 'timeout' in error.lower():
            error_type = 'è¶…æ—¶'
        else:
            error_type = error[:50]
        error_types[error_type] += 1

    for error_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True):
        print(f"  - {error_type}: {count} ä¸ª")


def retry_failed_products(failed_products, max_workers=3):
    """é‡æ–°çˆ¬å–å¤±è´¥çš„äº§å“"""
    logger = get_logger()

    # æå–äº§å“æ•°æ®
    products_to_retry = [item['item_data'] for item in failed_products]

    logger.info(f"\nå¼€å§‹é‡æ–°çˆ¬å– {len(products_to_retry)} ä¸ªå¤±è´¥çš„äº§å“...")

    # ä½¿ç”¨å¹¶è¡Œçˆ¬å–
    results = scrape_details_parallel(
        products=products_to_retry,
        scrape_detail_func=scrape_product_detail,
        max_workers=max_workers,
        retry_times=5,  # å¢åŠ é‡è¯•æ¬¡æ•°
        request_delay=(3, 6),  # å¢åŠ å»¶è¿Ÿï¼Œæé«˜æˆåŠŸç‡
        enable_headless=True
    )

    # æ£€æŸ¥å“ªäº›æˆåŠŸäº†
    success_count = 0
    still_failed = []

    for i, result in enumerate(results):
        original = products_to_retry[i]
        # æ£€æŸ¥æ˜¯å¦æˆåŠŸè·å–åˆ°è¯¦æƒ…
        if any(key in result for key in ['highlights', 'description', 'directions']):
            success_count += 1
        else:
            # ä»ç„¶å¤±è´¥ï¼Œä¿ç•™è®°å½•
            still_failed.append(failed_products[i])

    logger.info(
        f"\né‡çˆ¬ç»“æœ:\n"
        f"  - æˆåŠŸ: {success_count}/{len(products_to_retry)}\n"
        f"  - ä»å¤±è´¥: {len(still_failed)}/{len(products_to_retry)}"
    )

    # æ›´æ–°å¤±è´¥è®°å½•æ–‡ä»¶
    failed_file = project_root / "data" / "output" / "failed_products.json"
    if still_failed:
        with open(failed_file, 'w', encoding='utf-8') as f:
            json.dump(still_failed, f, ensure_ascii=False, indent=2)
        logger.info(f"\næ›´æ–°å¤±è´¥è®°å½•: {len(still_failed)} ä¸ªäº§å“ä»æœªæˆåŠŸ")
    else:
        # å…¨éƒ¨æˆåŠŸï¼Œåˆ é™¤å¤±è´¥è®°å½•æ–‡ä»¶
        failed_file.unlink()
        logger.info(f"\nğŸ‰ æ‰€æœ‰äº§å“éƒ½å·²æˆåŠŸçˆ¬å–ï¼å¤±è´¥è®°å½•å·²æ¸…ç©º")

    return results, success_count


def main():
    print("=" * 70)
    print("å¤±è´¥äº§å“é‡çˆ¬å·¥å…·")
    print("=" * 70)

    # åŠ è½½å¤±è´¥è®°å½•
    failed_products = load_failed_products()

    if not failed_products:
        print("\nâœ“ æ²¡æœ‰éœ€è¦é‡çˆ¬çš„äº§å“")
        return

    # æ˜¾ç¤ºå¤±è´¥æ‘˜è¦
    show_failed_summary(failed_products)

    # è¯¢é—®æ˜¯å¦é‡çˆ¬
    print(f"\n{'=' * 70}")
    response = input(f"æ˜¯å¦é‡æ–°çˆ¬å–è¿™ {len(failed_products)} ä¸ªå¤±è´¥çš„äº§å“ï¼Ÿ(y/n): ").strip().lower()

    if response != 'y':
        print("å–æ¶ˆæ“ä½œ")
        return

    # è¯¢é—®çº¿ç¨‹æ•°
    print("\næç¤º: å»ºè®®ä½¿ç”¨è¾ƒå°‘çš„çº¿ç¨‹æ•°å’Œè¾ƒé•¿çš„å»¶è¿Ÿæ¥æé«˜æˆåŠŸç‡")
    try:
        workers = input("å¹¶å‘çº¿ç¨‹æ•° (å»ºè®®2-3, é»˜è®¤2): ").strip() or "2"
        max_workers = min(max(int(workers), 1), 5)
    except ValueError:
        max_workers = 2

    # é‡æ–°çˆ¬å–
    results, success_count = retry_failed_products(failed_products, max_workers)

    # ä¿å­˜æˆåŠŸçš„ç»“æœ
    if success_count > 0:
        print(f"\n{'=' * 70}")
        save_option = input("æ˜¯å¦å°†æˆåŠŸçˆ¬å–çš„äº§å“ä¿å­˜åˆ°CSVï¼Ÿ(y/n): ").strip().lower()

        if save_option == 'y':
            import csv
            output_file = project_root / "data" / "output" / "retry_success.csv"

            fieldnames = [
                "äº§å“åç§°", "äº§å“äº®ç‚¹", "äº§å“ä»·æ ¼", "äº§å“å“ç‰Œ",
                "äº§å“å›¾", "äº§å“æè¿°", "äº§å“ç±»å‹", "ä½œç”¨éƒ¨ä½",
                "ç”¨æ³•è¯´æ˜", "è¥å…»æˆåˆ†", "é…æ–™è¡¨", "URL"
            ]

            with open(output_file, 'w', newline='', encoding='utf-8-sig') as f:
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()

                for product in results:
                    # åªä¿å­˜æˆåŠŸçš„
                    if any(key in product for key in ['highlights', 'description', 'directions']):
                        row = {
                            "äº§å“åç§°": product.get("name", ""),
                            "äº§å“ä»·æ ¼": product.get("price", ""),
                            "äº§å“äº®ç‚¹": product.get("highlights", ""),
                            "ç”¨æ³•è¯´æ˜": product.get("directions", ""),
                            "äº§å“å›¾": product.get("image", ""),
                            "äº§å“ç±»å‹": "",
                            "ä½œç”¨éƒ¨ä½": product.get("target_area", ""),
                            "é…æ–™è¡¨": product.get("ingredients", ""),
                            "äº§å“å“ç‰Œ": product.get("brand", ""),
                            "äº§å“æè¿°": product.get("description", ""),
                            "è¥å…»æˆåˆ†": product.get("nutritional_info", ""),
                            "URL": product.get("url", ""),
                        }
                        writer.writerow(row)

            print(f"âœ“ æˆåŠŸäº§å“å·²ä¿å­˜åˆ°: {output_file}")

    print(f"\n{'=' * 70}")
    print("å®Œæˆ!")
    print(f"{'=' * 70}")


if __name__ == "__main__":
    main()
